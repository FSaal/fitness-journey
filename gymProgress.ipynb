{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project my fitness progress over time will be analyzed.\n",
    "This is a bit tricky, since the data is stored in two different databases of two different apps (Progression and Workout Book?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading the data\n",
    "   1. Loading the gym app data\n",
    "   2. Loading weight data\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data\n",
    "## 1.1 Loading the gym app data\n",
    "\n",
    "CSV stands for comma separated values and is a file format, which is often used to represent data in a table structured form.\n",
    "However, since a comma is seen as a separator between two columns, a comma inside one cell leads to a wrong parsing.\n",
    "This can be fixed by replacing the comma with another value, e.g. a semicolon.\n",
    "\n",
    "Example of the problem\n",
    "\n",
    "![csv comma problem](res\\csv_comma_problem.png)\n",
    "\n",
    "The other problem was, that sometimes the comments contained a newline.\n",
    "\n",
    "![csv line problem](res\\csv_line_problem.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_progression_csv(input_file_path:Path, output_file_path=None) -> Path:\n",
    "    \"\"\"Makes the progression csv readable and returns the path to the fixed csv\"\"\"\n",
    "    with open(input_file_path, \"r\") as input_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        first_fix = fix_linebreaks(reader)\n",
    "        second_fix = replace_comma_in_comments(first_fix)\n",
    "\n",
    "    if not output_file_path:\n",
    "        output_file_path = f\"{input_file_path.stem}_fixed.csv\"\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        writer = csv.writer(output_file, lineterminator=\"\\n\")\n",
    "        [writer.writerow(row) for row in second_fix]\n",
    "    return output_file_path\n",
    "\n",
    "\n",
    "def fix_linebreaks(reader: csv.reader):\n",
    "    \"\"\"Revert line breaks and move them into one row.\n",
    "\n",
    "    When writing a comment with a line break in the progression app, the part after the line break\n",
    "    is written to a new line in the .csv file. This function detects all line breaks and replaces\n",
    "    the line break with '.  '\"\"\"\n",
    "    fixed_lines = [next(reader)]\n",
    "    for line in reader:\n",
    "        # Line break with empty line\n",
    "        if not line:\n",
    "            next_line = next(reader)\n",
    "            last_line = fixed_lines[-1]\n",
    "            fixed_lines[-1] = last_line[:-1] + [\". \".join([last_line[-1], next_line[0]])] + next_line[1:]\n",
    "        # Line break\n",
    "        elif not re.match(\"\\d{4}-\\d{2}-\\d{2}\", line[0]):\n",
    "            last_line = fixed_lines[-1]\n",
    "            fixed_lines[-1] = last_line[:-1] + [\". \".join([last_line[-1], line[0]])] + line[1:]\n",
    "        else:\n",
    "            fixed_lines.append(line)\n",
    "\n",
    "    return iter(fixed_lines)\n",
    "\n",
    "\n",
    "def replace_comma_in_comments(rows) -> list[list]:\n",
    "    \"\"\"Replace ',' in comments with ';'\"2022-04-18 20 04 14.csv\"\n",
    "\n",
    "    When writing a comment with a ',' in the progression app, the .csv file treats it as new entry.\n",
    "    This leads to a faulty parsing of the lines.\n",
    "    To fix this, the comma is replaced with ';'\"\"\"\n",
    "    header_line = next(rows)\n",
    "    column_count = \",\".join(header_line).count(\",\")\n",
    "    fixed_lines = [header_line]\n",
    "\n",
    "    for i, line in enumerate(rows):\n",
    "        # Convert from list to string\n",
    "        line = \",\".join(line)\n",
    "        comma_count = line.count(\",\")\n",
    "        # Lines where a comma was written in either set or session comment\n",
    "        if comma_count > column_count:\n",
    "            first_parts = line.split(\",\")[:14]\n",
    "            comment_parts = line.split(\",\")[14:-2]\n",
    "            end_parts = line.split(\",\")[-2:]\n",
    "\n",
    "            fixed_parts = [comment_parts[0]]\n",
    "            for part in comment_parts[1:]:\n",
    "                if part and part[0] == \" \":\n",
    "                    fixed_parts[-1] += \";\" + part\n",
    "                elif part and part[0].isdigit() and fixed_parts[-1][-1].isdigit():\n",
    "                    fixed_parts[-1] += \".\" + part\n",
    "                else:\n",
    "                    fixed_parts.append(part)\n",
    "\n",
    "            if len(fixed_parts) > 2:\n",
    "                raise ValueError(f\"Too many commas in line {i}: {line}\")\n",
    "\n",
    "            line = \",\".join(first_parts + fixed_parts + end_parts)\n",
    "\n",
    "        # Convert string back to list\n",
    "        line = line.split(\",\")\n",
    "        fixed_lines.append(line)\n",
    "\n",
    "    return fixed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filepath: str, name: str) -> pd.DataFrame:\n",
    "    \"\"\"Read a csv file as dataframe.\"\"\"\n",
    "    if name == GYMBOOK_NAME:\n",
    "        df = pd.read_csv(filepath, delimiter=\";\", decimal=\",\")\n",
    "    else:\n",
    "        df = pd.read_csv(filepath, delimiter=\",\", decimal=\",\")\n",
    "    return df\n",
    "\n",
    "# Data file of Progression app (android)\n",
    "PROGRESSION_NAME = \"progression_data\"\n",
    "GYMBOOK_NAME = \"gymbook_data\"\n",
    "file1 = Path('data/2023-04-27 18 58 40.csv')\n",
    "file1_fixed = fix_progression_csv(file1)\n",
    "df_progression = read_csv(file1_fixed, PROGRESSION_NAME)\n",
    "\n",
    "# Data file of GymBook app (iOS)\n",
    "# Note: sep=, has to be added as first line in the csv file\n",
    "# Also file has to be saved as utf-8 csv in Excel\n",
    "file2 = Path('data/GymBook-Logs-2023-04-08.csv')\n",
    "df_gymbook = read_csv(file2, GYMBOOK_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the two loaded dataframes.\n",
    "\n",
    "The progression dataframe ADD TEXT...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progression.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gymbook.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Loading the weight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weight = pd.read_csv(\"data/weight.csv\", delimiter=\";\")\n",
    "df_weight[\"Date\"] = pd.to_datetime(df_weight[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "df_weight.head(2)\n",
    "# px.scatter(df, x=\"Date\", y=\"Weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = df_weight[\"Date\"].iloc[-1]\n",
    "# end_date = df_weight[\"Date\"].iloc[0]\n",
    "# date_range = pd.date_range(start_date, end_date)[::-1]\n",
    "\n",
    "# dic = {\"Date\": date_range, \"Weight\": np.empty(len(date_range))}\n",
    "# df_new = pd.DataFrame(dic)\n",
    "# merge = pd.merge(df_weight, df_new, how=\"right\", on=\"Date\")\n",
    "# merge[\"Weight_x\"].update(\"Weight_y\")\n",
    "# merge.rename(columns={'Weight_x': 'Weight'}, inplace=True)\n",
    "# merge.drop(\"Weight_y\", axis=1, inplace=True)\n",
    "# merge[\"Weight\"].at[0] = 70.5\n",
    "# merge[\"Weight\"] = merge[\"Weight\"].astype(float)\n",
    "# px.scatter(x=merge[\"Date\"], y=merge[\"Weight\"].interpolate(method=\"polynomial\", order=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "### Remove unwanted columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gymbook app also wrote a line when the exercise was not performed.\n",
    "To get valid values those rows have to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_skipped_sets(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove sets from dataframe, which were not performed\"\"\"\n",
    "    skipped_sets = df[df[\"Ausgelassen\"] == \"Ja\"]\n",
    "    df_no_skipped_sets = df.drop(skipped_sets.index, errors=\"ignore\")\n",
    "    return df_no_skipped_sets\n",
    "\n",
    "df_gymbook = remove_skipped_sets(df_gymbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_columns(\n",
    "    df: pd.DataFrame, unneeded_columns: list = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Remove columns which do not hold any valuable information.\"\"\"\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    redundant_columns = constant_columns + unneeded_columns\n",
    "\n",
    "    df_compact = df.drop(redundant_columns, axis=1, errors=\"ignore\")\n",
    "    print(f\"Removed columns {redundant_columns}\")\n",
    "    return df_compact\n",
    "\n",
    "\n",
    "df_gymbook = remove_redundant_columns(\n",
    "    df_gymbook,\n",
    "    [\n",
    "        \"Muskelgruppen (Primäre)\",\n",
    "        \"Muskelgruppen (Sekundäre)\",\n",
    "        \"Satz / Aufwärmsatz / Abkühlungssatz\",\n",
    "    ],\n",
    ")\n",
    "# Before removing Set Duration, write the info in the repetitions columns, used for time-based exercises e.g. Plank\n",
    "df_progression[\"Repetitions\"].fillna(df_progression[\"Set Duration (s)\"], inplace=True)\n",
    "df_progression = remove_redundant_columns(df_progression, [\"Time\", \"Set Duration (s)\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data\n",
    "\n",
    "The columns of the gymbook app are in german, whereas the columns of the progression app are in english.\n",
    "Some columns represent the same and must just be renamed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Rename gymbook columns to match naming of progression app\"\"\"\n",
    "    column_name_mapping = {\n",
    "        \"Datum\": \"Date\",\n",
    "        \"Training\": \"Workout Name\",\n",
    "        \"Zeit\": \"Set Timestamp\",\n",
    "        \"Übung\": \"Exercise Name\",\n",
    "        \"Wiederholungen / Zeit\": \"Repetitions\",\n",
    "        \"Gewicht / Strecke\": \"Weight\",\n",
    "        \"Notizen\": \"Set Comment\",\n",
    "    }\n",
    "    df_renamed_cols = df.rename(columns=column_name_mapping)\n",
    "    return df_renamed_cols\n",
    "\n",
    "def convert_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert number columns to int / float\"\"\"\n",
    "    # Convert repetitions column from string to int\n",
    "    df[\"Repetitions\"] = df[\"Repetitions\"].str.extract(\"(\\d+)\").astype(int)\n",
    "    # Remove \"kg\" from weight column and convert from string to float\n",
    "    df[\"Weight\"] = df[\"Weight\"].str.extract(\"(\\d+,\\d+)\").replace(\",\", \".\", regex=True).astype(float)\n",
    "    return df\n",
    "\n",
    "def adapt_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Rename and convert gymbook columns to match progression columns\"\"\"\n",
    "    df = rename_columns(df)\n",
    "    df = convert_columns(df)\n",
    "    return df\n",
    "\n",
    "df_gymbook = adapt_columns(df_gymbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gymbook.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progression.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now there are two different columns for the time. One date column and one set column. It is better to have the information in one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_date_time_columns(\n",
    "    df: pd.DataFrame,\n",
    "    format_string: str,\n",
    "    date_col: str = \"Date\",\n",
    "    time_col: str = \"Set Timestamp\",\n",
    "):\n",
    "    \"\"\"Replace date and time column by one datetime column.\"\"\"\n",
    "    df[\"Time\"] = pd.to_datetime(df[date_col] + \" \" + df[time_col], format=format_string)\n",
    "    df_datetime = df.drop([date_col, time_col], axis=1)\n",
    "    return df_datetime\n",
    "\n",
    "\n",
    "# Convert and combine date / time columns into one datetime column\n",
    "df_progression = merge_date_time_columns(df_progression, \"%Y-%m-%d %H:%M:%S\")\n",
    "df_gymbook = merge_date_time_columns(df_gymbook, \"%d.%m.%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_progression.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gymbook.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since both dataframes are cleansed, it is time to check which unique information each dataframe holds.\n",
    "And if possible, to calculate the same information for the other dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns are unique for each df\n",
    "cols_only_in_progression = set(df_progression.columns).difference(\n",
    "    set(df_gymbook.columns)\n",
    ")\n",
    "cols_only_in_gymbook = set(df_gymbook.columns).difference(set(df_progression.columns))\n",
    "print(f\"Columns only in progression: {cols_only_in_progression}\")\n",
    "print(f\"Columns only in gymbook: {cols_only_in_gymbook}\")\n",
    "\n",
    "\n",
    "def extend_gymbook_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add Session Duration and Set Order column to gymbook df, to match progression df\"\"\"\n",
    "    # Calculate workout time using time difference between first and last set for each day\n",
    "    df[\"Session Duration (s)\"] = (\n",
    "        df.groupby(df[\"Time\"].dt.date)[\"Time\"]\n",
    "        .transform(lambda x: x.max() - x.min())\n",
    "        .dt.seconds\n",
    "    )\n",
    "    df[\"Set Order\"] = df.groupby([df[\"Time\"].dt.date, \"Exercise Name\"]).cumcount() + 1\n",
    "    return df\n",
    "\n",
    "df_gymbook = extend_gymbook_df(df_gymbook)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both dataframes can be merged.\n",
    "It also checked, if all columns have the correct dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_progression, df_gymbook])\n",
    "df = df.sort_values(\"Time\", ascending=False)\n",
    "\n",
    "# Remove NaNs\n",
    "df[\"Weight\"] = df[\"Weight\"].fillna(0).astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to find the same exercises with different names. E.g. in the gymbook app the squat is called \"Barbell Squats\" and in the gymbook app it is called \"Barbell Squat\"\n",
    "\n",
    "Gymbook uses plural instead of a singular for exercise names. Convert to singular and check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises_progression = set(df_progression[\"Exercise Name\"])\n",
    "exercises_gymbook = set(df_gymbook[\"Exercise Name\"])\n",
    "common_exercises = exercises_gymbook.intersection(exercises_progression)\n",
    "\n",
    "print(f\"{len(common_exercises)} exercises are in both: {common_exercises}\")\n",
    "exercises_gymbook_unique = exercises_gymbook.symmetric_difference(common_exercises)\n",
    "print(f\"{len(exercises_gymbook_unique)} Exercises are only in gymbook: {exercises_gymbook_unique}\")\n",
    "exercises_progression_unique = exercises_progression.symmetric_difference(common_exercises)\n",
    "print(f\"{len(exercises_progression_unique)} Exercises are only in progression: {exercises_progression_unique}\")\n",
    "\n",
    "\n",
    "def singularize(exercises: set[str]) -> dict:\n",
    "    \"\"\"Convert from plural form to singular form\"\"\"\n",
    "    # Plural form es but keep e\n",
    "    plural_exceptions = [\"lunges\", \"raises\"]\n",
    "    singles = []\n",
    "    for exercise in exercises:\n",
    "        if exercise[-2:] == \"es\":\n",
    "            singular_replacement = exercise[:-2]\n",
    "            singles.append([exercise, singular_replacement])\n",
    "        elif exercise[-1:] == \"s\" and not exercise[-2:] == \"ss\":\n",
    "            singular_replacement = exercise[:-1]\n",
    "            singles.append([exercise, singular_replacement])\n",
    "\n",
    "    map_plural_to_singular = dict(singles)\n",
    "    plural_exceptions = {\"Lunges\", \"Raises\"}\n",
    "    for exercise in map_plural_to_singular:\n",
    "        for exception in plural_exceptions:\n",
    "            if exception in exercise:\n",
    "                singular_replacement = exercise.replace(exception[:-2], exception[:-1])\n",
    "                map_plural_to_singular[exercise] = singular_replacement\n",
    "    return map_plural_to_singular\n",
    "\n",
    "\n",
    "map_gymbook_plural_to_singular = singularize(set(df_gymbook[\"Exercise Name\"]))\n",
    "\n",
    "# Convert some gymbook names to progression names\n",
    "map_gymbook_to_progression = {\n",
    "    \"Ab Wheel\": \"Ab Roller\",\n",
    "    \"Alternating Dumbbell Preacher Curl\": \"Alternating Dumbbell Curl\",\n",
    "    \"Arnold Press\": \"Arnold Dumbbell Press (Seated)\",\n",
    "    \"Back Extension\": \"Machine Hyperextension\",\n",
    "    \"Bulgarian Split Squat \": \"Bulgarian Split Squat\",\n",
    "    \"Cable Fly\": \"Cable Back Fly\",\n",
    "    \"Calf Press in Leg Press\": \"Machine Calf Press\",\n",
    "    \"Chin-Up\": \"Chinup\",\n",
    "    \"Concentration Curl\": \"Dumbbell Concentration Curl\",\n",
    "    \"Crunch\": \"Weighted Crunch\",\n",
    "    \"Decline Push-Up\": \"Decline Pushup\",\n",
    "    \"Dumbbell Lateral Raise\": \"Dumbbell Side Raise\",\n",
    "    \"Dumbbell Press\": \"Dumbbell Shoulder Press\",\n",
    "    \"Dumbbell Row\": \"Bent-Over Dumbbell Row\",\n",
    "    \"Dumbbell Skullcrusher\": \"Lying Dumbbell Skull Crusher\",\n",
    "    \"Hammer Curl\": \"Dumbbell Hammer Curl\",\n",
    "    \"Kneeling Cable Crunch\": \"Cable Crunch\",\n",
    "    \"Lat Pull-Down\": \"Machine Lat Pulldown\",\n",
    "    \"Leg Extension\": \"Machine Leg Extension\",\n",
    "    \"Leg Press\": \"Machine Leg Press\",\n",
    "    \"Low Cable One-Arm Lateral Raise\": \"Cable Side Raise\",\n",
    "    \"Lying Dumbbell Triceps Extension\": \"Dumbbell Triceps Extension\",\n",
    "    \"Lying EZ-Bar Triceps Extension\": \"Lying Barbell Skull Crusher\",\n",
    "    \"Lying Leg Curl\": \"Machine Lying Leg Curl\",\n",
    "    \"Machine Back Extension\": \"Machine Hyperextension\",\n",
    "    \"Machine Hip Abduction\": \"Machine Thigh Abduction (Out)\",\n",
    "    \"Machine Trunk Rotation\": \"Torso Rotation Machine\",\n",
    "    \"One-Leg Leg Extension\": \"Machine Single-Leg Extension\",\n",
    "    \"Power Clean\": \"Barbell Power Clean\",\n",
    "    \"Pullups Weighted \": \"Weighted Pullup\",\n",
    "    \"Push Down\": \"Cable Pushdown (with Bar Handle)\",\n",
    "    \"Push Press\": \"Barbell Push Press\",\n",
    "    \"Push-Up\": \"Pushup\",\n",
    "    \"Seated Leg Curl\": \"Machine Leg Curl\",\n",
    "    \"Seated Machine Hip Abduction\": \"Machine Thigh Abduction (Out)\",\n",
    "    \"Seated Machine Row\": \"Machine Row\",\n",
    "    \"Standing Calf Raise\": \"Machine Calf Raise\",\n",
    "    \"Standing Machine Calf Raise\": \"Machine Calf Raise\",\n",
    "    \"Wide-Grip Lat Pull-Down\": \"Wide-Grip Machine Lat Pulldown\",\n",
    "}\n",
    "\n",
    "# Convert some progression names to gymbook names\n",
    "map_progression_to_gymbook = {\n",
    "    \"Barbell Curl\": \"EZ-Bar Curl\",\n",
    "    \"Bent-Over Barbell Row\": \"Barbell Row\",\n",
    "    \"Butterfly Reverse\": \"Reverse Machine Fly\",\n",
    "    \"Cable Row\": \"Seated Cable Row\",\n",
    "    \"Dumbbell Pullover (Targeting back)\": \"Dumbbell Lat Pullover\",\n",
    "    \"Farmer's Walk (with Dumbbells)\": \"Farmers Walk\",\n",
    "    \"Farmer's Walk (with Weight Plate)\": \"Farmers Walk\",\n",
    "    \"Machine Calf Press\": \"Calf Press In Leg Press\",\n",
    "    \"Press around\": \"Press Around\",\n",
    "    \"Romanian Deadlift\": \"Barbell Romanian Deadlift\",\n",
    "    \"Stiff-Leg Deadlift (Wide Stance)\": \"Straight-Leg Barbell Deadlift\",\n",
    "    \"Sumo Deadlift\": \"Barbell Sumo Deadlift\",\n",
    "    \"Weighted pistol squat\": \"Pistol squat\",\n",
    "}\n",
    "\n",
    "# Convert some names to a value, which is in neither dataframe\n",
    "map_rename_in_both = {\n",
    "    # Gymbook\n",
    "    \"Close-Grip Lat Pull-Down\": \"Close-Grip Machine Lat Pull-Down\",\n",
    "    \"Machine Bench Press\": \"Seated Machine Bench Press\",\n",
    "    \"Parallel Bar Dip\": \"Dip\",\n",
    "    # Progression\n",
    "    \"Barbell Shrug (Behind the Back)\": \"Barbell Shrug\",\n",
    "    \"Chest Dip\": \"Dip\",\n",
    "    \"Machine Bench Press\": \"Seated Machine Bench Press\",\n",
    "}\n",
    "\n",
    "print(f\"At the beginning there are {df['Exercise Name'].nunique()} unique exercises\")\n",
    "\n",
    "df[\"Exercise Name\"].replace(map_gymbook_plural_to_singular, inplace=True)\n",
    "print(f\"After singularizing there are {df['Exercise Name'].nunique()} unique exercises\")\n",
    "\n",
    "df[\"Exercise Name\"].replace(map_gymbook_to_progression, inplace=True)\n",
    "print(f\"After mapping gymbook exercises to progression naming there are {df['Exercise Name'].nunique()} unique exercises\")\n",
    "\n",
    "df[\"Exercise Name\"].replace(map_progression_to_gymbook, inplace=True)\n",
    "print(f\"After mapping progression exercises to gymbook naming there are {df['Exercise Name'].nunique()} unique exercises\")\n",
    "\n",
    "df[\"Exercise Name\"].replace(map_rename_in_both, inplace=True)\n",
    "print(f\"After renaming exercises in both there are {df['Exercise Name'].nunique()} unique exercises\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct dtypes\n",
    "print(df.dtypes)\n",
    "df[\"Workout Name\"] = df[\"Workout Name\"].astype(\"category\")\n",
    "df[\"Exercise Name\"] = df[\"Exercise Name\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from german to english\n",
    "map_muscle_category_ger_eng = {\n",
    "    \"Arme\": \"Arms\",\n",
    "    \"Bauch\": \"Abs\",\n",
    "    \"Beine\": \"Legs\",\n",
    "    \"Brust\": \"Chest\",\n",
    "    \"Gesäss\": \"Glute\",\n",
    "    \"Rücken\": \"Back\",\n",
    "    \"Schultern\": \"Shoulders\",\n",
    "}\n",
    "df[\"Bereich\"].replace(map_muscle_category_ger_eng, inplace=True)\n",
    "df[\"Bereich\"].replace(np.nan, \"Undefined\", inplace=True)\n",
    "\n",
    "exercises_without_category = set(df[df[\"Bereich\"] == \"Undefined\"][\"Exercise Name\"])\n",
    "exercises_with_category = set(df[df[\"Bereich\"] != \"Undefined\"][\"Exercise Name\"])\n",
    "# Exercises which where mapped from gymbook to progression naming and did loose their Bereich\n",
    "exercises_with_lost_category = exercises_with_category.intersection(exercises_without_category)\n",
    "print(f\"{len(exercises_without_category)} have no category\")\n",
    "print(f\"{len(exercises_with_category)} have a category\")\n",
    "print(f\"{len(exercises_with_lost_category)} have only partially category mapping\")\n",
    "\n",
    "for exercise in exercises_with_lost_category:\n",
    "    muscle_category = next(iter(set(df[df[\"Exercise Name\"] == exercise][\"Bereich\"]) - {\"Undefined\"}))\n",
    "    df.loc[(df[\"Exercise Name\"] == exercise) & (df[\"Bereich\"] == \"Undefined\"), \"Bereich\"] = muscle_category\n",
    "    \n",
    "exercises_without_category = set(df[df[\"Bereich\"] == \"Undefined\"][\"Exercise Name\"])\n",
    "exercises_with_category = set(df[df[\"Bereich\"] != \"Undefined\"][\"Exercise Name\"])\n",
    "exercises_with_lost_category = exercises_with_category.intersection(exercises_without_category)\n",
    "print(f\"{len(exercises_without_category)} have no category\")\n",
    "print(f\"{len(exercises_with_category)} have a category\")\n",
    "print(f\"{len(exercises_with_lost_category)} have only partially category mapping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_exercise_to_muscle = {\n",
    "    \"Arms\": {\"Push\", \"Curl\", \"Kickback\", \"Triceps\"},\n",
    "    \"Back\": {\"Pull\", \"Row\", \"deadlift\"},\n",
    "    \"Chest\": {\"Bench\", \"Crossover\", \"Fly\"},\n",
    "    \"Legs\": {\"Calf\", \"Leg\", \"Squat\", \"Lunge\", \"Thigh\", \"Clean\"},\n",
    "    \"Shoulders\": {\"Shoulder\", \"Shrug\", \"Delt\", \"Arnold\", \"Raise\"},\n",
    "}\n",
    "\n",
    "for exercise in exercises_without_category:\n",
    "    counter = 0\n",
    "    muscle_categories = []\n",
    "    for category, keywords in map_exercise_to_muscle.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in exercise:\n",
    "                muscle_category = category\n",
    "                muscle_categories.append(category)\n",
    "                counter += 1\n",
    "    if counter == 1:\n",
    "        # print(f\"Mapping {exercise} to {muscle_category}\")\n",
    "        df.loc[df[\"Exercise Name\"] == exercise, \"Bereich\"] = muscle_category\n",
    "    elif counter > 1:\n",
    "        # Legs always wins\n",
    "        if \"Legs\" in muscle_categories:\n",
    "            df.loc[df[\"Exercise Name\"] == exercise, \"Bereich\"] = \"Legs\"\n",
    "        else:\n",
    "            print(f\"Problem with {exercise}. Found in {muscle_categories}. Skipping...\")\n",
    "    else:\n",
    "        pass\n",
    "        print(f\"No mapping for {exercise}\")\n",
    "\n",
    "# Solving conflicts\n",
    "map_conflicts = {\n",
    "    \"Shoulders\": {\"Cable Rear Delt Fly\"},\n",
    "    \"Back\": {\"Single-Arm Dumbbell Row on Bench\"},\n",
    "    \"Chest\": {\"Barbell Bench Press (with Raised Feet)\"}\n",
    "}\n",
    "# Map the rest manually\n",
    "manual_map = {\n",
    "    \"Abs\": {\n",
    "        \"Ab Complex\",\n",
    "        \"Bicycle Crunch\",\n",
    "        \"Burpee\",\n",
    "        \"Plank\",\n",
    "        \"Russian Twist\",\n",
    "        \"Standing Cable Lift\",\n",
    "    },\n",
    "    \"Back\": {\"Weighted Chinup\"},\n",
    "    \"Arms\": {\"Wrist curl (Roller)\"},\n",
    "}\n",
    "# map_conflicts.update(manual_map)\n",
    "\n",
    "for muscle_category, exercises in map_conflicts.items():\n",
    "    for exercise in exercises:\n",
    "        df.loc[df[\"Exercise Name\"] == exercise, \"Bereich\"] = muscle_category\n",
    "        \n",
    "for muscle_category, exercises in manual_map.items():\n",
    "    for exercise in exercises:\n",
    "        df.loc[df[\"Exercise Name\"] == exercise, \"Bereich\"] = muscle_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises_without_category = set(df[df[\"Bereich\"] == \"Undefined\"][\"Exercise Name\"])\n",
    "exercises_without_category_l = sorted(list(exercises_without_category))\n",
    "# exercises_without_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weight\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_map = {\n",
    "    0: \"Monday\",\n",
    "    1: \"Tuesday\",\n",
    "    2: \"Wednesday\",\n",
    "    3: \"Thursday\",\n",
    "    4: \"Friday\",\n",
    "    5: \"Saturday\",\n",
    "    6: \"Sunday\",\n",
    "}\n",
    "\n",
    "df[\"Weekday\"] = df[\"Time\"].dt.weekday.map(weekday_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([df[\"Time\"].dt.year, df[\"Time\"].dt.month, df[\"Time\"].dt.day]).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.groupby([df[\"Time\"].dt.year, df[\"Time\"].dt.month, df[\"Time\"].dt.date]).nunique().loc[(2022, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = df.groupby([df[\"Time\"].dt.year.rename(\"year\"), df[\"Time\"].dt.month.rename(\"month\")])[\"Time\"].apply(lambda x: x.dt.date.nunique())\n",
    "df_dates = df_dates.reset_index(level=[0,1])\n",
    "df_dates[\"datetime\"] = pd.to_datetime(df_dates[[\"year\", \"month\"]].assign(day=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise = \"Barbell Squat\"\n",
    "df_filtered_exercise = df[df[\"Exercise Name\"] == exercise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_date = df_filtered_exercise.groupby(df_filtered_exercise[\"Time\"].dt.date)\n",
    "def calculate_volumne(group):\n",
    "    return (group[\"Repetitions\"] * group[\"Weight\"]).sum()\n",
    "\n",
    "volumne = grouped_by_date.apply(calculate_volumne)\n",
    "# px.scatter(volumne,)\n",
    "df_v = pd.DataFrame(volumne)\n",
    "df_v.isna().sum()\n",
    "df_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date_string=  '2023-09-01'\n",
    "datetime.strptime(date_string, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_date = df_filtered_exercise.groupby(df_filtered_exercise[\"Time\"].dt.date)\n",
    "weekdays = pd.Categorical(grouped_by_date[\"Weekday\"].first(), categories=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "weekdays.sort_values()\n",
    "px.histogram(weekdays.sort_values())\n",
    "# px.bar(weekdays)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45e153cad1c143275aa145d11fa9c7b0054378bc6497ec01fffd1ae1288b92b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
